1. Gao *et al*. **AutoBERT-Zero**: usou uma estratégia de busca evolucionária pela primeira vez para descobrir um backbone novo e universal de LLM.
2. Ganesan *et al*. **SuperShaper**: realiza a busca pelas dimensões das unidades ocultas de cada camada do Transformer.
3. Yin *et al*. **AutoTinyBERT**: busca pelos hiper-parâmetros de cada camada do modelo.
4. Javaheripi *et al*. **LiteTransformerSearch**: também realizar a busca pelos hiper-parâmetros das camadas do modelo.